{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files Downloaded from Gutenberg\n",
    "pg14640.txt McGuffey's First Eclectic Reader, Revised Edition by William Holmes McGuffey http://www.gutenberg.org/cache/epub/14640/pg14640.txt\n",
    "\n",
    "pg14880.txt McGuffey's Fourth Eclectic Reader by William Holmes McGuffey http://www.gutenberg.org/cache/epub/14880/pg14880.txt\n",
    "\n",
    "pg16751.txt McGuffey's Sixth Eclectic Reader by William Holmes McGuffey http://www.gutenberg.org/cache/epub/16751/pg16751.txt\n",
    "\n",
    "pg19721.txt The Literary World Seventh Reader by Browne, Metcalf, and Withers http://www.gutenberg.org/cache/epub/19721/pg19721.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loader and Tokenizer Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "def open_Gutenberg(url):\n",
    "    response = request.urlopen(url)\n",
    "    return response.read().decode('utf8')\n",
    "\n",
    "def loadAndPrepReader(file_contents):\n",
    "    file_contents = file_contents.split('\\n')   # split into lines\n",
    "    file_contents = [line.strip('\\r') for line in file_contents]  # remove carriage-returns\n",
    "    start_index = [i for i, s in enumerate(file_contents) if '*** START OF THIS PROJECT' in s] # get start index\n",
    "    end_index = [i for i, s in enumerate(file_contents) if '*** END OF THIS PROJECT' in s] # get end index\n",
    "    return file_contents[start_index[0]+1:end_index[0]-1] # returned sliced file_contents\n",
    "\n",
    "def tokenizer(file_contents):\n",
    "    tokenized_words = [word_tokenize(line) for line in file_contents] # tokenize our raw list of lines\n",
    "    unroll = [item for sublist in tokenized_words for item in sublist] # unroll into single list\n",
    "    return [w for w in unroll if w.isalnum()] # drop special characters, punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcGuffey_one = tokenizer(loadAndPrepReader(open_Gutenberg(\"http://www.gutenberg.org/cache/epub/14640/pg14640.txt\")))\n",
    "mcGuffey_four = tokenizer(loadAndPrepReader(open_Gutenberg(\"http://www.gutenberg.org/cache/epub/14880/pg14880.txt\")))\n",
    "mcGuffey_six = tokenizer(loadAndPrepReader(open_Gutenberg(\"http://www.gutenberg.org/cache/epub/16751/pg16751.txt\")))\n",
    "literaryWorld_seven = tokenizer(loadAndPrepReader(open_Gutenberg(\"http://www.gutenberg.org/cache/epub/19721/pg19721.txt\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW1 \"Text Difficulty\" Measurement Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns percentage of unique words divided by total words, \"lexical diversity\"\n",
    "# I don't like that this lexical_diversity function doesn't account for case, but following the example in the\n",
    "# NLTK book\n",
    "\n",
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)\n",
    "\n",
    "def vocab_size(text):\n",
    "    return len(set(word.lower() for word in text)) # this does account for case\n",
    "\n",
    "def percentage(count, total):\n",
    "    return 100 * count / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Lexical Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The lexical diversity of McGuffey's First Eclectic Reader: {0:.2f}\".format(lexical_diversity(mcGuffey_one)))\n",
    "print(\"The lexical diversity of McGuffey's Fourth Eclectic Reader: {0:.2f}\".format(lexical_diversity(mcGuffey_four)))\n",
    "print(\"The lexical diversity of McGuffey's Sixth Eclectic Reader: {0:.2f}\".format(lexical_diversity(mcGuffey_six)))\n",
    "print(\"The lexical diversity of The Literary World Seventh Reader: {0:.2f}\".format(lexical_diversity(literaryWorld_seven)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results seem to align with my expectations. That is - for more basic readers the number of unique words is large(r) compared to the total number of words. This means that the unique words take up more of the total words, which could be a proxy for the level of the writing style."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The vocabulary size of McGuffey's First Eclectic Reader: {0}\".format(vocab_size(mcGuffey_one)))\n",
    "print(\"The vocabulary size of McGuffey's Fourth Eclectic Reader: {0}\".format(vocab_size(mcGuffey_four)))\n",
    "print(\"The vocabulary size of McGuffey's Sixth Eclectic Reader: {0}\".format(vocab_size(mcGuffey_six)))\n",
    "print(\"The vocabulary size of The Literary World Seventh Reader: {0}\".format(vocab_size(literaryWorld_seven)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also seems to align with my expectations. The more advanced readers have a higher total vocabulary size. This is clear examining from first, fourth, and sixth. The seventh reader seems to drop back down, but may simply be related to the fact that it's a different series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tIn Python, create a method for scoring the vocabulary size of a text, and normalize the score from 0 to 1. It does not matter what method you use for normalization as long as you explain it in a short paragraph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary Size & Lexical Diversity Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first issue is that lexical diversity on its own is a poor measure of \"lexical richness\" because usually texts containing a large number of tokens will have lower lexical diversity scores simply based on the fact that the writer must re-use function words (words that have litle lexical meaning). A second issue could be that a text contains a very large vocabulary, but is succint in it's writing, thus producing a high lexical diversity score (but could be quite advanced in terms of the vocabulary). To solve the first issue lexical diversity makes more sense when comparing texts that have similar total token size. The second issue can be analyzed by looking at both lexical diversity and the vocabulary size. Thus I would argue that both measures are required to appropriately measure text difficulty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Vocabulary Size for Multiple Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def normalize(x):\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "    denom = max(x) - min(x) \n",
    "    return list((x - min(x)) / denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_texts = [mcGuffey_one, mcGuffey_four, mcGuffey_six, literaryWorld_seven]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[vocab_size(text) for text in my_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_normal = normalize([vocab_size(text) for text in my_texts])\n",
    "vocab_size_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My normalization utilizes a pretty common approach to feature scaling following: Xnew = (X - Xmin) / (Xmax - Xmin). This will make the largest value equal to 1 and the smallest value equal to 0 with the intermediate values falling between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_word_vocab_size(text, length):\n",
    "    return len(set(word.lower() for word in text if len(word) > length))\n",
    "\n",
    "def long_word_vocab_words(text, length):\n",
    "    return sorted(set(word.lower() for word in text if len(word) > length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_word_vocab_size(mcGuffey_one, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_word_vocab_words(mcGuffey_one, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[long_word_vocab_size(text, 7) for text in my_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_word_vocab_normal = normalize([long_word_vocab_size(text, 7) for text in my_texts])\n",
    "long_word_vocab_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll consider words longer than 7 characters to be \"long words\" since we're dealing with adolescent level reading material. I re-use my normalization technique from the total vocabulary size here to normalize the long word vocabulary counts across the readers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination \"Text Difficulty Score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_diversity_scores = [lexical_diversity(text) for text in my_texts]  # save lexical diversity to list\n",
    "lexical_diversity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lexical_diversity_scores = np.asarray(lexical_diversity_scores)\n",
    "#lexical_diversity_scores = list(1 - lexical_diversity_scores)\n",
    "#lexical_diversity_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in HW1, lexical diversity seems problematic as longer and more complicated texts would have a disproportionate score simply based on the number of function words contributing to total length of the text. It seems the length of the text is going to dillute the lexical diversity score in this regard. This was shown in my analysis - texts with low lexical diversity scores seem to be more complex and should have higher lexical diversity scores, but are being misrepresented based on length.\n",
    "\n",
    "I chose not to manipulate the lexical diversity scores from HW1 as I think that's the spirit of HW2.\n",
    "\n",
    "I averaged each of the scores: lexical diversity, normalized vocab, normalize long-word vocab, to produce final \"Text Difficulty Score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = np.asarray(vocab_size_normal) + np.asarray(long_word_vocab_normal) + np.asarray(lexical_diversity_scores)\n",
    "text_difficulty_score = list(total_scores / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The Text Difficulty Score of McGuffey's First Eclectic Reader: {0:.2f}\".format(text_difficulty_score[0]))\n",
    "print(\"The Text Difficulty Score of McGuffey's Fourth Eclectic Reader: {0:.2f}\".format(text_difficulty_score[1]))\n",
    "print(\"The Text Difficulty Score of McGuffey's Sixth Eclectic Reader: {0:.2f}\".format(text_difficulty_score[2]))\n",
    "print(\"The Text Difficulty Score of The Literary World Seventh Reader: {0:.2f}\".format(text_difficulty_score[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These final Text Difficulty Scores still seem to generally align with our expectations of the complexity of the reader as grade level increases. The normalization generally magnifies the differences between the measured complexity of this set of readers. This score also seems to magnify the differences between McGuffey's Sixth Eclectic Reader and The Literary World Seventh Reader, which by this measure seems to show The Literary World Seventh Reader be significantly easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Interview questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  2.,  4.,  6.,  8., 10., 12., 14., 16., 18., 20.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0,20.1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 in np.arange(0,20,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nterms = int(input(\"How many terms? \"))\n",
    "\n",
    "# first two terms\n",
    "n1, n2 = 0, 1\n",
    "count = 0\n",
    "\n",
    "# check if the number of terms is valid\n",
    "if nterms <= 0:\n",
    "   print(\"Please enter a positive integer\")\n",
    "elif nterms == 1:\n",
    "   print(\"Fibonacci sequence upto\",nterms,\":\")\n",
    "   print(n1)\n",
    "else:\n",
    "   print(\"Fibonacci sequence:\")\n",
    "   while count < nterms:\n",
    "       print(n1)\n",
    "       nth = n1 + n2\n",
    "       # update values\n",
    "       n1 = n2\n",
    "       n2 = nth\n",
    "       count -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
